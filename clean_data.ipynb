{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data important features:\n",
    "position - (Integer) - Hotel position on Expedia's search results page. This is only provided for the training data, but not the test data.\n",
    "click_bool - (Boolean) - 1 if the user clicked on the property, 0 if not.\n",
    "booking_bool - (Boolean) - 1 if the user booked the property, 0 if not.\n",
    "gross_booking_usd - (Float) - Total value of the transaction. This can differ from the price_usd due to taxes, fees, conventions on multiple day bookings and purchase of a room type other than the one shown in the search.\n",
    "\n",
    "More info on: https://www.kaggle.com/c/expedia-personalized-sort/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
      "0        1  2013-04-04 08:32:15       12                          187   \n",
      "1        1  2013-04-04 08:32:15       12                          187   \n",
      "2        1  2013-04-04 08:32:15       12                          187   \n",
      "3        1  2013-04-04 08:32:15       12                          187   \n",
      "4        1  2013-04-04 08:32:15       12                          187   \n",
      "\n",
      "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
      "0                      NaN                   NaN              219      893   \n",
      "1                      NaN                   NaN              219    10404   \n",
      "2                      NaN                   NaN              219    21315   \n",
      "3                      NaN                   NaN              219    27348   \n",
      "4                      NaN                   NaN              219    29604   \n",
      "\n",
      "   prop_starrating  prop_review_score  ...  comp6_rate_percent_diff  \\\n",
      "0                3                3.5  ...                      NaN   \n",
      "1                4                4.0  ...                      NaN   \n",
      "2                3                4.5  ...                      NaN   \n",
      "3                2                4.0  ...                      NaN   \n",
      "4                4                3.5  ...                      NaN   \n",
      "\n",
      "   comp7_rate  comp7_inv  comp7_rate_percent_diff  comp8_rate  comp8_inv  \\\n",
      "0         NaN        NaN                      NaN         0.0        0.0   \n",
      "1         NaN        NaN                      NaN         0.0        0.0   \n",
      "2         NaN        NaN                      NaN         0.0        0.0   \n",
      "3         NaN        NaN                      NaN        -1.0        0.0   \n",
      "4         NaN        NaN                      NaN         0.0        0.0   \n",
      "\n",
      "   comp8_rate_percent_diff  click_bool  gross_bookings_usd  booking_bool  \n",
      "0                      NaN           0                 NaN             0  \n",
      "1                      NaN           0                 NaN             0  \n",
      "2                      NaN           0                 NaN             0  \n",
      "3                      5.0           0                 NaN             0  \n",
      "4                      NaN           0                 NaN             0  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4958347, 54)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4958347 entries, 0 to 4958346\n",
      "Data columns (total 54 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   srch_id                      int64  \n",
      " 1   date_time                    object \n",
      " 2   site_id                      int64  \n",
      " 3   visitor_location_country_id  int64  \n",
      " 4   visitor_hist_starrating      float64\n",
      " 5   visitor_hist_adr_usd         float64\n",
      " 6   prop_country_id              int64  \n",
      " 7   prop_id                      int64  \n",
      " 8   prop_starrating              int64  \n",
      " 9   prop_review_score            float64\n",
      " 10  prop_brand_bool              int64  \n",
      " 11  prop_location_score1         float64\n",
      " 12  prop_location_score2         float64\n",
      " 13  prop_log_historical_price    float64\n",
      " 14  position                     int64  \n",
      " 15  price_usd                    float64\n",
      " 16  promotion_flag               int64  \n",
      " 17  srch_destination_id          int64  \n",
      " 18  srch_length_of_stay          int64  \n",
      " 19  srch_booking_window          int64  \n",
      " 20  srch_adults_count            int64  \n",
      " 21  srch_children_count          int64  \n",
      " 22  srch_room_count              int64  \n",
      " 23  srch_saturday_night_bool     int64  \n",
      " 24  srch_query_affinity_score    float64\n",
      " 25  orig_destination_distance    float64\n",
      " 26  random_bool                  int64  \n",
      " 27  comp1_rate                   float64\n",
      " 28  comp1_inv                    float64\n",
      " 29  comp1_rate_percent_diff      float64\n",
      " 30  comp2_rate                   float64\n",
      " 31  comp2_inv                    float64\n",
      " 32  comp2_rate_percent_diff      float64\n",
      " 33  comp3_rate                   float64\n",
      " 34  comp3_inv                    float64\n",
      " 35  comp3_rate_percent_diff      float64\n",
      " 36  comp4_rate                   float64\n",
      " 37  comp4_inv                    float64\n",
      " 38  comp4_rate_percent_diff      float64\n",
      " 39  comp5_rate                   float64\n",
      " 40  comp5_inv                    float64\n",
      " 41  comp5_rate_percent_diff      float64\n",
      " 42  comp6_rate                   float64\n",
      " 43  comp6_inv                    float64\n",
      " 44  comp6_rate_percent_diff      float64\n",
      " 45  comp7_rate                   float64\n",
      " 46  comp7_inv                    float64\n",
      " 47  comp7_rate_percent_diff      float64\n",
      " 48  comp8_rate                   float64\n",
      " 49  comp8_inv                    float64\n",
      " 50  comp8_rate_percent_diff      float64\n",
      " 51  click_bool                   int64  \n",
      " 52  gross_bookings_usd           float64\n",
      " 53  booking_bool                 int64  \n",
      "dtypes: float64(34), int64(19), object(1)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# print size of data\n",
    "print(train_data.shape)\n",
    "\n",
    "# display data information\n",
    "train_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non ordinal integers that should become strings:\n",
    "- srch_destination_id\n",
    "- site_id \n",
    "- visitor_location_country_id\n",
    "- prop_country_id\n",
    "- srch_destination_id \n",
    "\n",
    "Integers that should become boolean:\n",
    "- prop_brand_bool\n",
    "- srch_saturday_night_bool\n",
    "- random_bool\n",
    "\n",
    "To predict:\n",
    "position: Hotel position on Expedia's search results page. This is only provided for the training data, but not the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform integers to strings for categorical data\n",
    "train_data['srch_destination_id'] = train_data['srch_destination_id'].astype(str)\n",
    "train_data['site_id'] = train_data['site_id'].astype(str)\n",
    "train_data['visitor_location_country_id'] = train_data['visitor_location_country_id'].astype(str)\n",
    "train_data['prop_country_id'] = train_data['prop_country_id'].astype(str)\n",
    "train_data['prop_id'] = train_data['prop_id'].astype(str)\n",
    "train_data['srch_destination_id'] = train_data['srch_destination_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform integers to boleans\n",
    "train_data[\"prop_brand_bool\"] = train_data[\"prop_brand_bool\"].astype(bool)\n",
    "train_data[\"srch_saturday_night_bool\"] = train_data[\"srch_saturday_night_bool\"].astype(bool)\n",
    "train_data[\"random_bool\"] = train_data[\"random_bool\"].astype(bool)\n",
    "train_data[\"promotion_flag\"] = train_data[\"promotion_flag\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id 0.0\n",
      "date_time 0.0\n",
      "site_id 0.0\n",
      "visitor_location_country_id 0.0\n",
      "visitor_hist_starrating 0.949203635808466\n",
      "visitor_hist_adr_usd 0.9489773507178905\n",
      "prop_country_id 0.0\n",
      "prop_id 0.0\n",
      "prop_starrating 0.0\n",
      "prop_review_score 0.0014851723770038683\n",
      "prop_brand_bool 0.0\n",
      "prop_location_score1 0.0\n",
      "prop_location_score2 0.2199015115319682\n",
      "prop_log_historical_price 0.0\n",
      "position 0.0\n",
      "price_usd 0.0\n",
      "promotion_flag 0.0\n",
      "srch_destination_id 0.0\n",
      "srch_length_of_stay 0.0\n",
      "srch_booking_window 0.0\n",
      "srch_adults_count 0.0\n",
      "srch_children_count 0.0\n",
      "srch_room_count 0.0\n",
      "srch_saturday_night_bool 0.0\n",
      "srch_query_affinity_score 0.935985520981085\n",
      "orig_destination_distance 0.32425766086964064\n",
      "random_bool 0.0\n",
      "comp1_rate 0.9758125036428471\n",
      "comp1_inv 0.9738705258022482\n",
      "comp1_rate_percent_diff 0.9809535314894258\n",
      "comp2_rate 0.5916639154137457\n",
      "comp2_inv 0.5703671001646314\n",
      "comp2_rate_percent_diff 0.8878178554264153\n",
      "comp3_rate 0.6905646176034069\n",
      "comp3_inv 0.6670281446619206\n",
      "comp3_rate_percent_diff 0.9046462460170698\n",
      "comp4_rate 0.9380079691881186\n",
      "comp4_inv 0.9306900061653611\n",
      "comp4_rate_percent_diff 0.9735625602645398\n",
      "comp5_rate 0.5517915547257988\n",
      "comp5_inv 0.5240308917467857\n",
      "comp5_rate_percent_diff 0.8303670557950059\n",
      "comp6_rate 0.9515651082911301\n",
      "comp6_inv 0.9473663299482671\n",
      "comp6_rate_percent_diff 0.9806036164875108\n",
      "comp7_rate 0.9364005786605899\n",
      "comp7_inv 0.9281167695605007\n",
      "comp7_rate_percent_diff 0.9720642786799714\n",
      "comp8_rate 0.61344899822461\n",
      "comp8_inv 0.5991601636593809\n",
      "comp8_rate_percent_diff 0.8760211820592629\n",
      "click_bool 0.0\n",
      "gross_bookings_usd 0.9720894886945186\n",
      "booking_bool 0.0\n"
     ]
    }
   ],
   "source": [
    "# print missing values in each column\n",
    "for col in train_data.columns:\n",
    "    # print percentage of missing values\n",
    "    print(col, train_data[col].isnull().sum()/train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitor_hist_starrating 0.949203635808466\n",
      "visitor_hist_adr_usd 0.9489773507178905\n",
      "srch_query_affinity_score 0.935985520981085\n",
      "comp1_rate 0.9758125036428471\n",
      "comp1_inv 0.9738705258022482\n",
      "comp1_rate_percent_diff 0.9809535314894258\n",
      "comp2_rate 0.5916639154137457\n",
      "comp2_inv 0.5703671001646314\n",
      "comp2_rate_percent_diff 0.8878178554264153\n",
      "comp3_rate 0.6905646176034069\n",
      "comp3_inv 0.6670281446619206\n",
      "comp3_rate_percent_diff 0.9046462460170698\n",
      "comp4_rate 0.9380079691881186\n",
      "comp4_inv 0.9306900061653611\n",
      "comp4_rate_percent_diff 0.9735625602645398\n",
      "comp5_rate 0.5517915547257988\n",
      "comp5_inv 0.5240308917467857\n",
      "comp5_rate_percent_diff 0.8303670557950059\n",
      "comp6_rate 0.9515651082911301\n",
      "comp6_inv 0.9473663299482671\n",
      "comp6_rate_percent_diff 0.9806036164875108\n",
      "comp7_rate 0.9364005786605899\n",
      "comp7_inv 0.9281167695605007\n",
      "comp7_rate_percent_diff 0.9720642786799714\n",
      "comp8_rate 0.61344899822461\n",
      "comp8_inv 0.5991601636593809\n",
      "comp8_rate_percent_diff 0.8760211820592629\n",
      "gross_bookings_usd 0.9720894886945186\n"
     ]
    }
   ],
   "source": [
    "# print all columns that contain more than 50% missing values\n",
    "for col in train_data.columns:\n",
    "    # print percentage of missing values\n",
    "    if train_data[col].isnull().sum()/train_data.shape[0] > 0.5:\n",
    "        print(col, train_data[col].isnull().sum()/train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all integers to floats to compute means and z-scores\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'int64':\n",
    "        train_data[col] = train_data[col].astype(float)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            srch_id  visitor_hist_starrating  visitor_hist_adr_usd  \\\n",
      "count  4.958347e+06            251866.000000         252988.000000   \n",
      "mean   1.663666e+05                 3.374334            176.022659   \n",
      "std    9.611223e+04                 0.692519            107.254493   \n",
      "min    1.000000e+00                 1.410000              0.000000   \n",
      "25%    8.293600e+04                 2.920000            109.810000   \n",
      "50%    1.665070e+05                 3.450000            152.240000   \n",
      "75%    2.497240e+05                 3.930000            213.490000   \n",
      "max    3.327850e+05                 5.000000           1958.700000   \n",
      "\n",
      "       prop_starrating  prop_review_score  prop_location_score1  \\\n",
      "count     4.958347e+06       4.950983e+06          4.958347e+06   \n",
      "mean      3.180525e+00       3.777777e+00          2.872589e+00   \n",
      "std       1.051024e+00       1.050329e+00          1.531011e+00   \n",
      "min       0.000000e+00       0.000000e+00          0.000000e+00   \n",
      "25%       3.000000e+00       3.500000e+00          1.790000e+00   \n",
      "50%       3.000000e+00       4.000000e+00          2.770000e+00   \n",
      "75%       4.000000e+00       4.500000e+00          4.040000e+00   \n",
      "max       5.000000e+00       5.000000e+00          6.980000e+00   \n",
      "\n",
      "       prop_location_score2  prop_log_historical_price      position  \\\n",
      "count          3.867999e+06               4.958347e+06  4.958347e+06   \n",
      "mean           1.303852e-01               4.317913e+00  1.685624e+01   \n",
      "std            1.594634e-01               1.834869e+00  1.042566e+01   \n",
      "min            0.000000e+00               0.000000e+00  1.000000e+00   \n",
      "25%            1.900000e-02               4.450000e+00  8.000000e+00   \n",
      "50%            6.900000e-02               4.910000e+00  1.600000e+01   \n",
      "75%            1.805000e-01               5.310000e+00  2.600000e+01   \n",
      "max            1.000000e+00               6.210000e+00  4.000000e+01   \n",
      "\n",
      "          price_usd  ...  comp6_rate_percent_diff     comp7_rate  \\\n",
      "count  4.958347e+06  ...             96174.000000  315348.000000   \n",
      "mean   2.542096e+02  ...                17.250473       0.145969   \n",
      "std    1.600124e+04  ...                31.160313       0.578202   \n",
      "min    0.000000e+00  ...                 2.000000      -1.000000   \n",
      "25%    8.500000e+01  ...                 6.000000       0.000000   \n",
      "50%    1.220000e+02  ...                11.000000       0.000000   \n",
      "75%    1.849600e+02  ...                18.000000       1.000000   \n",
      "max    1.972633e+07  ...              1620.000000       1.000000   \n",
      "\n",
      "           comp7_inv  comp7_rate_percent_diff    comp8_rate     comp8_inv  \\\n",
      "count  356422.000000            138515.000000  1.916654e+06  1.987503e+06   \n",
      "mean        0.083202                19.433267 -6.089936e-02  9.962752e-03   \n",
      "std         0.316722                54.370221  4.691723e-01  2.029142e-01   \n",
      "min        -1.000000                 2.000000 -1.000000e+00 -1.000000e+00   \n",
      "25%         0.000000                 7.000000  0.000000e+00  0.000000e+00   \n",
      "50%         0.000000                12.000000  0.000000e+00  0.000000e+00   \n",
      "75%         0.000000                20.000000  0.000000e+00  0.000000e+00   \n",
      "max         1.000000              9900.000000  1.000000e+00  1.000000e+00   \n",
      "\n",
      "       comp8_rate_percent_diff    click_bool  gross_bookings_usd  booking_bool  \n",
      "count            614730.000000  4.958347e+06       138390.000000  4.958347e+06  \n",
      "mean                 22.430384  4.474858e-02          386.283316  2.791051e-02  \n",
      "std                 895.965854  2.067514e-01          821.190577  1.647165e-01  \n",
      "min                   2.000000  0.000000e+00            0.000000  0.000000e+00  \n",
      "25%                   7.000000  0.000000e+00          124.000000  0.000000e+00  \n",
      "50%                  11.000000  0.000000e+00          218.400000  0.000000e+00  \n",
      "75%                  17.000000  0.000000e+00          429.790000  0.000000e+00  \n",
      "max              149400.000000  1.000000e+00       159292.380000  1.000000e+00  \n",
      "\n",
      "[8 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a table for all numerical data with mean, median, highest, lowest and standard deviation\n",
    "num_describtion = train_data.describe()\n",
    "print(num_describtion)\n",
    "\n",
    "# save to latex table\n",
    "import os\n",
    "if not os.path.exists('latex'):\n",
    "    os.makedirs('latex')\n",
    "num_describtion.to_latex('latex/num_describtion.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             unique        most occuring  \\\n",
      "date_time                    198615  2012-11-02 14:04:51   \n",
      "site_id                          34                    5   \n",
      "visitor_location_country_id     210                  219   \n",
      "prop_country_id                 172                  219   \n",
      "prop_id                      129113               104517   \n",
      "srch_destination_id           18127                 8192   \n",
      "\n",
      "                             most occuring frequency       least occuring  \\\n",
      "date_time                                   0.000019  2013-02-07 11:25:00   \n",
      "site_id                                     0.622386                    8   \n",
      "visitor_location_country_id                 0.583358                  150   \n",
      "prop_country_id                             0.611116                  165   \n",
      "prop_id                                     0.000475               108653   \n",
      "srch_destination_id                         0.014084                27364   \n",
      "\n",
      "                             least occuring frequency  \n",
      "date_time                                1.008401e-06  \n",
      "site_id                                  6.252084e-06  \n",
      "visitor_location_country_id              1.613441e-06  \n",
      "prop_country_id                          4.033602e-07  \n",
      "prop_id                                  2.016801e-07  \n",
      "srch_destination_id                      1.008401e-06  \n"
     ]
    }
   ],
   "source": [
    "# get number of unique categories, most occuring, least occuring and percentage of most occuring category for categorical data\n",
    "dict_cat = {}\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        unique = train_data[col].nunique()\n",
    "        moc = train_data[col].value_counts().idxmax()\n",
    "        moc_freq = train_data[col].value_counts().max()/train_data.shape[0]\n",
    "        loc = train_data[col].value_counts().idxmin()\n",
    "        loc_freq = train_data[col].value_counts().min()/train_data.shape[0]\n",
    "        \n",
    "        dict_cat[col] = [unique, moc, moc_freq, loc, loc_freq]\n",
    "    \n",
    "# create table for categorical data\n",
    "cat_describtion = pd.DataFrame.from_dict(dict_cat, orient='index', columns=['unique', 'most occuring', 'most occuring frequency', 'least occuring', 'least occuring frequency'])\n",
    "\n",
    "# save to latex\n",
    "cat_describtion.to_latex('cat_describtion.tex')\n",
    "\n",
    "print(cat_describtion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id float64\n",
      "date_time object\n",
      "site_id object\n",
      "visitor_location_country_id object\n",
      "visitor_hist_starrating float64\n",
      "visitor_hist_adr_usd float64\n",
      "prop_country_id object\n",
      "prop_id object\n",
      "prop_starrating float64\n",
      "prop_review_score float64\n",
      "prop_brand_bool bool\n",
      "prop_location_score1 float64\n",
      "prop_location_score2 float64\n",
      "prop_log_historical_price float64\n",
      "position float64\n",
      "price_usd float64\n",
      "promotion_flag bool\n",
      "srch_destination_id object\n",
      "srch_length_of_stay float64\n",
      "srch_booking_window float64\n",
      "srch_adults_count float64\n",
      "srch_children_count float64\n",
      "srch_room_count float64\n",
      "srch_saturday_night_bool bool\n",
      "srch_query_affinity_score float64\n",
      "orig_destination_distance float64\n",
      "random_bool bool\n",
      "comp1_rate float64\n",
      "comp1_inv float64\n",
      "comp1_rate_percent_diff float64\n",
      "comp2_rate float64\n",
      "comp2_inv float64\n",
      "comp2_rate_percent_diff float64\n",
      "comp3_rate float64\n",
      "comp3_inv float64\n",
      "comp3_rate_percent_diff float64\n",
      "comp4_rate float64\n",
      "comp4_inv float64\n",
      "comp4_rate_percent_diff float64\n",
      "comp5_rate float64\n",
      "comp5_inv float64\n",
      "comp5_rate_percent_diff float64\n",
      "comp6_rate float64\n",
      "comp6_inv float64\n",
      "comp6_rate_percent_diff float64\n",
      "comp7_rate float64\n",
      "comp7_inv float64\n",
      "comp7_rate_percent_diff float64\n",
      "comp8_rate float64\n",
      "comp8_inv float64\n",
      "comp8_rate_percent_diff float64\n",
      "click_bool float64\n",
      "gross_bookings_usd float64\n",
      "booking_bool float64\n"
     ]
    }
   ],
   "source": [
    "# print all column names and their data type\n",
    "for col in train_data.columns:\n",
    "    print(col, train_data[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename date time column to month (january, february, march, april, may, june, july, august, september, october, november, december)\n",
    "train_data['date_time'] = pd.to_datetime(train_data['date_time'])\n",
    "train_data['date_time'] = train_data['date_time'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the columns prop_starrating and prop_review_score, a 0 represents a missing value and should be replaced by nan\n",
    "train_data['prop_starrating'] = train_data['prop_starrating'].replace(0, np.nan)\n",
    "train_data['prop_review_score'] = train_data['prop_review_score'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean of the two columns prop_location_score1 and prop_location_score2 \n",
    "train_data['prop_location_score2'] = train_data['prop_location_score2'].fillna(train_data['prop_location_score1'])\n",
    "train_data['prop_location_score1'] = train_data['prop_location_score1'].fillna(train_data['prop_location_score2'])\n",
    "train_data['prop_location_score'] = train_data[['prop_location_score2', 'prop_location_score1']].mean(axis=1)\n",
    "train_data = train_data.drop(['prop_location_score1', 'prop_location_score2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_rate mean is the mean of all not nan values in all columns that contain comb_rate\n",
    "train_data['comb_rate'] = train_data[['comp1_rate', 'comp2_rate', 'comp3_rate', 'comp4_rate', 'comp5_rate', 'comp6_rate', 'comp7_rate', 'comp8_rate']].sum(axis=1, skipna=True)\n",
    "train_data['comb_rate_percentage_diff'] = train_data[['comp1_rate_percent_diff', 'comp2_rate_percent_diff', 'comp3_rate_percent_diff', 'comp4_rate_percent_diff', 'comp5_rate_percent_diff', 'comp6_rate_percent_diff', 'comp7_rate_percent_diff', 'comp8_rate_percent_diff']].mean(axis=1, skipna=True)\n",
    "train_data[\"comb_inv\"] = train_data[['comp1_inv', 'comp2_inv', 'comp3_inv', 'comp4_inv', 'comp5_inv', 'comp6_inv', 'comp7_inv', 'comp8_inv']].sum(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['comp1_rate', 'comp2_rate', 'comp3_rate', 'comp4_rate', 'comp5_rate', 'comp6_rate', 'comp7_rate', 'comp8_rate'], axis=1)\n",
    "train_data = train_data.drop(['comp1_rate_percent_diff', 'comp2_rate_percent_diff', 'comp3_rate_percent_diff', 'comp4_rate_percent_diff', 'comp5_rate_percent_diff', 'comp6_rate_percent_diff', 'comp7_rate_percent_diff', 'comp8_rate_percent_diff'], axis=1)\n",
    "train_data = train_data.drop(['comp1_inv', 'comp2_inv', 'comp3_inv', 'comp4_inv', 'comp5_inv', 'comp6_inv', 'comp7_inv', 'comp8_inv'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that contain more than 50% missing values\n",
    "train_data = train_data.dropna(thresh=train_data.shape[1]*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitor_hist_starrating 0.949203635808466\n",
      "visitor_hist_adr_usd 0.9489773507178905\n",
      "srch_query_affinity_score 0.935985520981085\n",
      "orig_destination_distance 0.32425766086964064\n",
      "gross_bookings_usd 0.9720894886945186\n",
      "comb_rate_percentage_diff 0.681246592866534\n"
     ]
    }
   ],
   "source": [
    "# remove all columns that contain more than 30% missing values\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].isnull().sum()/train_data.shape[0] > 0.30:\n",
    "        print(col, train_data[col].isnull().sum()/train_data.shape[0])\n",
    "        \n",
    "        train_data = train_data.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# handle missing values \n",
    "for col in train_data.columns:\n",
    "    \n",
    "    # check if numerical\n",
    "    if train_data[col].dtype == 'float64' or train_data[col].dtype == 'int64':   \n",
    "        train_data[col] = train_data[col].fillna(train_data[col].mean())\n",
    "        \n",
    "        # TODO: not always mean, sometimes median or mode\n",
    "    \n",
    "    # check if categorical\n",
    "    if train_data[col].dtype == 'object' or train_data[col].dtype == 'bool':\n",
    "        train_data[col] = train_data[col].fillna(train_data[col].value_counts().idxmax())\n",
    "\n",
    "# check if there are still missing values\n",
    "print(train_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('plots'):\n",
    "#     os.makedirs('plots')\n",
    "\n",
    "# # plot all the categorical data\n",
    "# for col in train_data.columns:\n",
    "#     if train_data[col].dtype == 'object':\n",
    "#         plt.figure()\n",
    "#         train_data[col].value_counts().plot(kind='bar')\n",
    "#         plt.title(col)\n",
    "#         plt.savefig('plots/' + col + '.png')\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in train_data.columns:\n",
    "    \n",
    "#     # check if column is categorical\n",
    "#     if train_data[column].dtype == 'object':\n",
    "        \n",
    "#         # check if there is a subcategory with less than 5 occurences\n",
    "#         for subcategory in train_data[column].unique():\n",
    "#             if train_data[train_data[column] == subcategory].shape[0] < 5:\n",
    "#                 print(column, subcategory, train_data[train_data[column] == subcategory].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove the columns ... and ... that are not in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle bins with less than 5 occurences \n",
    "# TODO: merge or to many different bins: \n",
    "# visitor_location_country_id and prop_country_id object to larger region\n",
    "# site_id?\n",
    "# prop_id?\n",
    "# srch_destination_id?\n",
    "# --> use k-means clustering to cluster these into bins with more than 5 occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot each numerical feature \n",
    "# for col in train_data.columns:\n",
    "#     if train_data[col].dtype == 'float64':\n",
    "#         plt.figure()\n",
    "#         plt.hist(train_data[col])\n",
    "#         plt.title(col)\n",
    "#         plt.savefig('plots/' + col + '.png')\n",
    "#         plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO transformation of features based on trend analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data in data folder\n",
    "train_data.to_csv('data/train_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
