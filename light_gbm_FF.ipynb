{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the LabelEncoder from sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "balance_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id                        0\n",
      "month                          0\n",
      "site_id                        0\n",
      "visitor_location_country_id    0\n",
      "prop_country_id                0\n",
      "prop_id                        0\n",
      "prop_starrating                0\n",
      "prop_review_score              0\n",
      "prop_brand_bool                0\n",
      "prop_log_historical_price      0\n",
      "position                       0\n",
      "price_usd                      0\n",
      "promotion_flag                 0\n",
      "srch_length_of_stay            0\n",
      "srch_booking_window            0\n",
      "srch_adults_count              0\n",
      "srch_children_count            0\n",
      "srch_room_count                0\n",
      "srch_saturday_night_bool       0\n",
      "orig_destination_distance      0\n",
      "random_bool                    0\n",
      "mean_position                  0\n",
      "perc_clicked                   0\n",
      "perc_booked                    0\n",
      "target                         0\n",
      "rating_relto_region            0\n",
      "rating_relto_search            0\n",
      "review_relto_search            0\n",
      "review_relto_region            0\n",
      "price_per_night                0\n",
      "price_rel_to_region            0\n",
      "price_rel_to_search            0\n",
      "rel_distance                   0\n",
      "prop_location_score            0\n",
      "comb_rate                      0\n",
      "comb_inv                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_data_df = pd.read_csv('data/train_cleaned.csv') # cleaned data gebruiken\n",
    "test_data_df = pd.read_csv('data/test_cleaned.csv') # cleaned data gebruiken\n",
    "\n",
    "# print missing values\n",
    "print(train_data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_df \n",
    "test_data = test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srch_id', 'month', 'site_id', 'visitor_location_country_id',\n",
      "       'prop_country_id', 'prop_id', 'prop_starrating', 'prop_review_score',\n",
      "       'prop_brand_bool', 'prop_log_historical_price', 'position', 'price_usd',\n",
      "       'promotion_flag', 'srch_length_of_stay', 'srch_booking_window',\n",
      "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
      "       'srch_saturday_night_bool', 'orig_destination_distance', 'random_bool',\n",
      "       'mean_position', 'perc_clicked', 'perc_booked', 'target',\n",
      "       'rating_relto_region', 'rating_relto_search', 'review_relto_search',\n",
      "       'review_relto_region', 'price_per_night', 'price_rel_to_region',\n",
      "       'price_rel_to_search', 'rel_distance', 'prop_location_score',\n",
      "       'comb_rate', 'comb_inv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print columns of train data\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srch_id', 'month', 'site_id', 'visitor_location_country_id',\n",
      "       'prop_country_id', 'prop_id', 'prop_starrating', 'prop_review_score',\n",
      "       'prop_brand_bool', 'prop_log_historical_price', 'price_usd',\n",
      "       'promotion_flag', 'srch_length_of_stay', 'srch_booking_window',\n",
      "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
      "       'srch_saturday_night_bool', 'orig_destination_distance', 'random_bool',\n",
      "       'mean_position', 'perc_clicked', 'perc_booked', 'rating_relto_region',\n",
      "       'rating_relto_search', 'review_relto_search', 'review_relto_region',\n",
      "       'price_per_night', 'price_rel_to_region', 'price_rel_to_search',\n",
      "       'rel_distance', 'prop_location_score', 'comb_rate', 'comb_inv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print columns of test data\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'position', 'target'}\n"
     ]
    }
   ],
   "source": [
    "# check if test and train have same columns\n",
    "print(set(train_data.columns) - set(test_data.columns))\n",
    "\n",
    "# drop all columns that are not in test from train with exception of 'target'\n",
    "drop_columns = set(train_data.columns) - set(test_data.columns) \n",
    "drop_columns.remove('target')\n",
    "train_data = train_data.drop(drop_columns, axis=1)\n",
    "\n",
    "# remove property id's from train and test (it is not a predictor, just an identifier)\n",
    "train_data = train_data.drop(['prop_id'], axis=1)\n",
    "test_prop = test_data['prop_id'] # save property id's for later use\n",
    "test_data = test_data.drop(['prop_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform booleans and ordinal cat features to numeric ['prop_brand_bool', 'promotion_flag', 'srch_destination_id', 'srch_saturday_night_bool', 'random_bool']\n",
    "train_data['prop_brand_bool'] = train_data['prop_brand_bool'].astype(int)\n",
    "train_data['promotion_flag'] = train_data['promotion_flag'].astype(int)\n",
    "train_data['srch_saturday_night_bool'] = train_data['srch_saturday_night_bool'].astype(int)\n",
    "train_data['random_bool'] = train_data['random_bool'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop('site_id', axis=1)\n",
    "test_data = test_data.drop('visitor_location_country_id', axis=1)\n",
    "test_data = test_data.drop('prop_country_id', axis=1)\n",
    "train_data = train_data.drop('site_id', axis=1)\n",
    "train_data = train_data.drop('visitor_location_country_id', axis=1)\n",
    "train_data = train_data.drop('prop_country_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cannot use one hot encoding here sadly, because we have too many unique values in the categorical features\n",
    "categorical_features = ['month']        # TODO may become more if we include above deleted features\n",
    "\n",
    "# first encode month to representimg integers (1-12) instead of names\n",
    "months = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\n",
    "train_data['month'] = train_data['month'].map(months)\n",
    "test_data['month'] = test_data['month'].map(months)\n",
    "\n",
    "# encode with cyclic encoding\n",
    "train_data['month'] = train_data['month'].apply(lambda x: np.sin(x*(2.*np.pi/12)))\n",
    "test_data['month'] = test_data['month'].apply(lambda x: np.sin(x*(2.*np.pi/12)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns missing in test data compared to train data:  {'target'}\n"
     ]
    }
   ],
   "source": [
    "# print what columns are missing in test data compared to train data\n",
    "print('Columns missing in test data compared to train data: ', set(train_data.columns) - set(test_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "\n",
    "# balance data    \n",
    "if balance_data:\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for lightgbm\n",
    "groups_train = X_train.groupby('srch_id').size().values\n",
    "groups_valid = X_valid.groupby('srch_id').size().values\n",
    "lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features, group=groups_train, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_valid, y_valid, categorical_feature=categorical_features, group=groups_valid, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5161\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain's ndcg@5: 0.688796\tvalid's ndcg@5: 0.946817\n",
      "[20]\ttrain's ndcg@5: 0.692278\tvalid's ndcg@5: 0.947423\n",
      "[30]\ttrain's ndcg@5: 0.695575\tvalid's ndcg@5: 0.948075\n",
      "[40]\ttrain's ndcg@5: 0.698772\tvalid's ndcg@5: 0.948706\n",
      "[50]\ttrain's ndcg@5: 0.701988\tvalid's ndcg@5: 0.949319\n",
      "[60]\ttrain's ndcg@5: 0.704438\tvalid's ndcg@5: 0.949776\n",
      "[70]\ttrain's ndcg@5: 0.706426\tvalid's ndcg@5: 0.950171\n",
      "[80]\ttrain's ndcg@5: 0.708078\tvalid's ndcg@5: 0.950442\n",
      "[90]\ttrain's ndcg@5: 0.709642\tvalid's ndcg@5: 0.950688\n",
      "[100]\ttrain's ndcg@5: 0.710996\tvalid's ndcg@5: 0.950893\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [5],\n",
    "    'force_col_wise': True,\n",
    "    'is_unbalance': True,\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                verbose_eval=10, # GET NDCG@5 EVALUATION SCORE EVERY 10 ROUNDS \n",
    "                valid_sets=[lgb_train, lgb_valid],\n",
    "                valid_names=['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [  1   0  63  37   7 282 116  28  48  54  39  22  31   8  58 136  83 275\n",
      " 225 126 220 129  58  80  57 334  67 379  26  11]\n",
      "Feature names: ['srch_id', 'month', 'prop_starrating', 'prop_review_score', 'prop_brand_bool', 'prop_log_historical_price', 'price_usd', 'promotion_flag', 'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool', 'orig_destination_distance', 'random_bool', 'mean_position', 'perc_clicked', 'perc_booked', 'rating_relto_region', 'rating_relto_search', 'review_relto_search', 'review_relto_region', 'price_per_night', 'price_rel_to_region', 'price_rel_to_search', 'rel_distance', 'prop_location_score', 'comb_rate', 'comb_inv']\n",
      "Selected features:\n",
      "['prop_location_score' 'price_rel_to_search' 'prop_log_historical_price'\n",
      " 'perc_clicked' 'perc_booked' 'rating_relto_search' 'random_bool'\n",
      " 'review_relto_search' 'rating_relto_region' 'price_usd']\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "feature_importance = gbm.feature_importance()\n",
    "feature_names = gbm.feature_name()\n",
    "print('Feature importances:', feature_importance)\n",
    "print('Feature names:', feature_names)\n",
    "# Sort feature importance in descending order\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Select the top K features\n",
    "K = 10  # Select top K features\n",
    "selected_features = np.take(feature_names, sorted_indices[:K])\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# make sure srch id is still in the data\n",
    "if 'srch_id' not in selected_features:\n",
    "    selected_features = np.append(selected_features, 'srch_id')\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train[selected_features], y_train, group=groups_train, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_valid[selected_features], y_valid, group=groups_valid, free_raw_data=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "c:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Wrong type(str) or unknown name(month) in categorical_feature",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-113db4d8251e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# perform lightgbm training again with selected features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m gbm = lgb.train(params,\n\u001b[0m\u001b[0;32m      3\u001b[0m                 \u001b[0mlgb_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# GET NDCG@5 EVALUATION SCORE EVERY 10 ROUNDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2603\u001b[0m                 )\n\u001b[0;32m   2604\u001b[0m             \u001b[1;31m# construct booster object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2605\u001b[1;33m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2606\u001b[0m             \u001b[1;31m# copy the parameters from train_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1813\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1814\u001b[0m                 \u001b[1;31m# create train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m                 self._lazy_init(self.data, label=self.label,\n\u001b[0m\u001b[0;32m   1816\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agnes\\anaconda3_nieuw\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1507\u001b[0m                     \u001b[0mcategorical_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1509\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1510\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcategorical_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcat_alias\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_ConfigAliases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"categorical_feature\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Wrong type(str) or unknown name(month) in categorical_feature"
     ]
    }
   ],
   "source": [
    "# perform lightgbm training again with selected features\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                verbose_eval=10, # GET NDCG@5 EVALUATION SCORE EVERY 10 ROUNDS\n",
    "                valid_sets=[lgb_train, lgb_valid],\n",
    "                valid_names=['train', 'valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = gbm.predict(test_data, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank predictions per search id\n",
    "test_data['pred'] = y_pred\n",
    "\n",
    "# re-add prop id\n",
    "test_data['prop_id'] = test_prop\n",
    "\n",
    "# sort predictions by search id and prediction\n",
    "test_data = test_data.sort_values(['srch_id', 'pred'], ascending = [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data[['srch_id', 'prop_id']]\n",
    "df['srch_id'] = df['srch_id'].astype('int')\n",
    "df['prop_id'] = df['prop_id'].astype('int')\n",
    "\n",
    "# drop index\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to csv\n",
    "if balance_data:\n",
    "    df.to_csv('submission/submission_gbm_FF_balanced.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    df.to_csv('submission/submission_gbm_FF.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
